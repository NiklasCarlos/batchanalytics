---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---


```{r setup}

library(batchanalytics)
library(bupaR)
library(bamalog)
library(tidyr)


```

Load sample eventlog 


```{r}

csv = system.file("exdata", "sample_data_1.csv", package = "batchanalytics")

csv_log = read.csv(csv)

task_log <- csv_log


```


detect batching behaviour and create a task log

add documentation why seq_list

```{r}


result_log <- my_detect_batching(task_log)



```



```{r}
#head(result_log)

# refactor one method that gets result_log as input

# split cases according to there batching behaviour -> dataframe format

df_logSim <- result_log %>%
    group_by(case_id) %>%
    filter(any( batch_type == "simultaneous")) %>% arrange(case_id)
    

df_logSeq <- result_log %>%
    group_by(case_id) %>%
    filter(any( batch_type == "sequential")) %>% arrange(case_id)


df_logConc <- result_log %>%
    group_by(case_id) %>%
    filter(any( batch_type == "concurrent")) %>% arrange(case_id)

#how to find cases where no batching is used?

# log- groupby case - filter any where batchtype != sim || seq|| conc



#new function for code refactoring
#get_batching_data(batch_type,result_log)


```




###batch processing metrics



```{r}

#create event log for further analysis elogSim <-....


elogSim <- df_logSim %>%
 #   mutate(instance_id = 1:nrow(.)) %>% # maybe try case_id for mutate
    gather(status, timestamp,  start, complete)  %>%
    eventlog(
        case_id = "case_id",
        activity_id = "activity",
        activity_instance_id = "instance_id",
        lifecycle_id = "status",
        timestamp = "timestamp",
        resource_id = "resource"
    )

elogSeq <- df_logSeq %>%
  #  mutate(instance_id = 1:nrow(.)) %>% # maybe try case_id for mutate
    gather(status, timestamp,  start, complete)  %>%
    eventlog(
        case_id = "case_id",
        activity_id = "activity",
        activity_instance_id = "instance_id",
        lifecycle_id = "status",
        timestamp = "timestamp",
        resource_id = "resource"
    )


elogConc <- df_logConc %>%
   # mutate(case_id = 1:nrow(.)) %>% # maybe try case_id for mutate
    gather(status, timestamp, start, complete)  %>% # arrival omitted , seems to be same as start
    eventlog(
        case_id = "case_id",
        activity_id = "activity",
        activity_instance_id = "instance_id",
        lifecycle_id = "status",
        timestamp = "timestamp",
        resource_id = "resource"
    )


elog <- result_log  %>%
    gather(status, timestamp, start, complete)  %>% # arrival omitted , seems to be same as start
    eventlog(
        case_id = "case_id",
        activity_id = "activity",
        activity_instance_id = "instance_id",
        lifecycle_id = "status",
        timestamp = "timestamp",
        resource_id = "resource"
    )




```


##show process model with batching behaviour

```{r}


elog %>% process_map()


#identfy which activites are performed with batching behaviour and if possible highlight in output graph or give an additional text output

```





## Cycle Time

The throughput time is the time form the very first event to the last event of a case. The levels at which it can be computed are log, trace, or case.

(overall cycle time, see pic bupR waiting time included)


```{r}
#cycle time function without bupaR


#view github implementation of bupaR 
# compare to niels function implementation

#result_log %>% group_by("case_id") %>% 


```



```{r}
#when writing method consider that not always all batch types are included and also no batching possible -> when plotting and creating boxplot create a generic approach#


# f체r modularit채t keep event log cration seperate from other functions 

#evtl cycle time selber funktion ohne event log schreiben -> von jeden case start - endzeit (groubby case , start - end , -> mean() an niels orientieren) 채hnlich f체r processing time -< vorher #ABER data spliten in "nobatching " vs andere batch types


sim <- elogSim %>%
    throughput_time("log")
 

seq <- elogSeq %>%
    throughput_time("log")
  
conc <- elogConc %>% 
      throughput_time("log")
     



 boxplot(sim, seq, conc,xlab = "batch type", ylab = "Throughput Time", names = c("parallel", "sequential", "concurrent")  )

```




##processing time
processing time: the sum of the duration of all activity instances[bupaR]


```{r}


#processing time

sim <- elogSim %>%
processing_time("log") 

seq <- elogSeq %>%
processing_time("log")  

conc <- elogConc %>% 
processing_time("log")     


boxplot(sim, seq, conc,xlab = "batch type", ylab = "processing Time", names = c("parallel", "sequential", "concurrent")  )



```


#idle time
idle time: the time when no activity instance is active



```{r}


sim <- elogSim %>%
idle_time("log", units = "days")

seq <- elogSeq %>%
idle_time("log", units = "days")

conc <- elogConc %>% 
idle_time("log", units = "days")

boxplot(sim, seq, conc,xlab = "batch type", ylab = "idle Time", names = c("parallel", "sequential", "concurrent")  )

 


```


#Metric cycle time efficiency
Ratio of overall processing time relative to the overall cycle time


```{r}
#cycle time efficiency



# processing time / throughput time


cycle_time_efficiency <- (elog %>% processing_time("log")) / (elog %>% throughput_time("log"))



print(cycle_time_efficiency)
```



##metric batch frequency

This metrics shows .....

```{r}
#test batch frequency



metric_frequency(result_log, "B", "WorkerB_#0", "concurrent", FALSE )
```



```{r}

#test batch size
#metric_frequency(result_log, "Registration", "r1", "concurrent", FALSE )

metric_batch_size(result_log, "B", "WorkerB_#0", "concurrent", exclude_singletons = TRUE)

```



```{r}
# Metric - Activity duration
metric_activity_duration(result_log, "B", "WorkerB_#0", "concurrent")



```
```{r}

#create event log for bupaR

  #result_log %>% eventlog( case_id = "case_id", activity_id = "activity")


```




---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---


```{r setup}

library(batchanalytics)
library(bupaR)
library(bamalog)
library(tidyr)


```

Load sample eventlog 


```{r}

csv = system.file("exdata", "sample_data_1.csv", package = "batchanalytics")

csv_log = read.csv(csv)

task_log <- csv_log


```


detect batching behaviour and create a task log

add documentation why seq_list

```{r}


# Create seq_tolerated_gap_list (gap of 0 seconds is allowed)
seq_tolerated_gap_list <- seq_tolerated_gap_list_generator(task_log = task_log, 
                                                           seq_tolerated_gap_value = 0)

subsequence_list <- enumerate_subsequences(task_log, 0)
# Use the following line for using frequent sequence mining instead
# subsequence_list <- identify_frequent_sequences(task_log, 0)

# Detect batching behavior
result_log <- detect_batching(task_log = task_log,
                             act_seq_tolerated_gap_list = seq_tolerated_gap_list,
                             timestamp_format = "yyyy-mm-dd hh:mm:ss",
                             numeric_timestamps = FALSE,
                             log_and_model_based = TRUE,
                             subsequence_list = subsequence_list,
                             subsequence_type = "enum",
                             # use `mine` to use frequence sequence mining
                             # subsequence_type = "mine",
                             within_case_seq_tolerated_gap = 0,
                             between_cases_seq_tolerated_gap = 0,
                             show_progress = F)
```



```{r}
#head(result_log)

# refactor one method that gets result_log as input

# split cases according to there batching behaviour -> dataframe format

df_logSim <- result_log %>%
    group_by(case_id) %>%
    filter(any( batch_type == "simultaneous")) %>% arrange(case_id)
    

df_logSeq <- result_log %>%
    group_by(case_id) %>%
    filter(any( batch_type == "sequential")) %>% arrange(case_id)


df_logConc <- result_log %>%
    group_by(case_id) %>%
    filter(any( batch_type == "concurrent")) %>% arrange(case_id)


```




###batch processing metrics



```{r}

#create event log for further analysis elogSim <-....


elogSim <- df_logSim %>%
 #   mutate(instance_id = 1:nrow(.)) %>% # maybe try case_id for mutate
    gather(status, timestamp,  start, complete)  %>%
    eventlog(
        case_id = "case_id",
        activity_id = "activity",
        activity_instance_id = "instance_id",
        lifecycle_id = "status",
        timestamp = "timestamp",
        resource_id = "resource"
    )

elogSeq <- df_logSeq %>%
  #  mutate(instance_id = 1:nrow(.)) %>% # maybe try case_id for mutate
    gather(status, timestamp,  start, complete)  %>%
    eventlog(
        case_id = "case_id",
        activity_id = "activity",
        activity_instance_id = "instance_id",
        lifecycle_id = "status",
        timestamp = "timestamp",
        resource_id = "resource"
    )


elogConc <- df_logConc %>%
   # mutate(case_id = 1:nrow(.)) %>% # maybe try case_id for mutate
    gather(status, timestamp, start, complete)  %>% # arrival omitted , seems to be same as start
    eventlog(
        case_id = "case_id",
        activity_id = "activity",
        activity_instance_id = "instance_id",
        lifecycle_id = "status",
        timestamp = "timestamp",
        resource_id = "resource"
    )




```

## Cycle Time

The throughput time is the time form the very first event to the last event of a case. The levels at which it can be computed are log, trace, or case.

```{r}

#when writing method consider that not always all batch types are included and also no batching possible -> when plotting and creating boxplot create a generic approach

elogSim %>%
    throughput_time("log") %>%
    plot()

elogSeq %>%
    throughput_time("log") %>%
    plot()

elogConc %>% 
      throughput_time("log") %>%
      plot()



```

```{r}

#test plot all in one

sim <- elogSim %>%
    throughput_time("log")
 

seq <- elogSeq %>%
    throughput_time("log")
  
conc <- elogConc %>% 
      throughput_time("log")
     
ts <- c(sim, seq , conc)

elogSim %>%
    throughput_time("log")

class(elogSim %>%
    throughput_time("log"))

 boxplot(sim, seq, conc,xlab = "batch type", ylab = "Throughput Time", names = c("parallel", "sequential", "concurrent")  )

```


##processing time


```{r}

# try through put time for each log collect in c() and than plot boxplot


#plot processing time and compare different batch behaviour
#log   %>% processing_time("activity") %>% plot()

```

##metric batch frequency

This metrics shows .....

```{r}
#test batch frequency



metric_frequency(result_log, "B", "WorkerB_#0", "concurrent", FALSE )
```



```{r}

#test batch size
#metric_frequency(result_log, "Registration", "r1", "concurrent", FALSE )

metric_batch_size(result_log, "B", "WorkerB_#0", "concurrent", exclude_singletons = TRUE)

```



```{r}
# Metric - Activity duration
metric_activity_duration(result_log, "B", "WorkerB_#0", "concurrent")



```
```{r}

#create event log for bupaR

  #result_log %>% eventlog( case_id = "case_id", activity_id = "activity")


```



